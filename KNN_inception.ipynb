{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "KNN_inception.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOQxdEj3BxDA"
      },
      "source": [
        "# KNN\n",
        "\n",
        "This notebook aims to use a pre-trained network in order to train a KNN-algorithm to make the final predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcGRbzNS8fkY"
      },
      "source": [
        "#Uncomment the line bellow only if it is necesssary\n",
        "!unzip drive/MyDrive/hackathon-isae-2021-patch-retrieval.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvgaepM4B2Ax",
        "outputId": "ca098a26-4912-4ab8-dda4-5daa43d10181"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAE0y0bx7yZV"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "from typing import List,Optional,Callable\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import sys\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJcsSu3OBxDQ"
      },
      "source": [
        "## Preparation\n",
        "### Model loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOjP9KEo8EVB"
      },
      "source": [
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x\n",
        "    \n",
        "class MetricResnet(nn.Module):\n",
        "    def __init__(self, backbone: nn.Module):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_1 = nn.Linear(512 * 7 * 7, 128)\n",
        "        self.activation = nn.ReLU()\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.backbone(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear_1(x)\n",
        "        x = F.normalize(x, p=2, dim=1)\n",
        "        return x\n",
        "  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAdqgFqb7-B2"
      },
      "source": [
        "def model_inference(model:nn.Module, loader, device='cuda'):\n",
        "    model.eval()\n",
        "    list_pred = []\n",
        "    list_path_name = []\n",
        "    with torch.no_grad():\n",
        "        for image,path in tqdm_notebook(loader):\n",
        "            image = image.to(device)\n",
        "            pred = model(image)\n",
        "            pred = pred.view(-1) # BATCH SIZE EQUAL TO 1\n",
        "            list_pred.append(pred.detach().cpu().numpy())\n",
        "            list_path_name.append(path)\n",
        "    return list_pred,list_path_name"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToJImhHO8JkK"
      },
      "source": [
        "path_model = \"/content/inception_20ep_margin2_lr-3_batch128_workers8.pt\"\n",
        "embedding_model = torch.load(path_model)#,map_location=torch.device('cpu'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx1GEDW1BxDU"
      },
      "source": [
        "### Data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duH04yyRBxDV"
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, list_path: List[int], transform: Optional[Callable]=None):\n",
        "        self.list_path = list_path\n",
        "        if transform is None:\n",
        "            self.transform = transforms.ToTensor()\n",
        "        else:\n",
        "            self.transform = transform\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.list_path)\n",
        "    def __getitem__(self, index:int):\n",
        "        path = self.list_path[index]\n",
        "        image = Image.open(path)\n",
        "        image = self.transform(image)\n",
        "        final_path = path.split(\"/\")[-1]\n",
        "        return image,final_path"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ainS_xA9C5Xd"
      },
      "source": [
        "choose one of the two options below:\n",
        "\n",
        "**for inception or resnet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kt23jKA8W5a"
      },
      "source": [
        "path_train = sorted(glob(\"Train/Train/*.png\"))\n",
        "images_train = ImageDataset(path_train)\n",
        "loader_train = DataLoader(images_train,batch_size=1,num_workers = 2)\n",
        "list_pred_train, list_path_train = model_inference(embedding_model,loader_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8heKE6Z8qNO"
      },
      "source": [
        "path_test = sorted(glob(\"Test/Test/*.png\"))\n",
        "images_test = ImageDataset(path_test)\n",
        "loader_test = DataLoader(images_test,batch_size=1,num_workers = 2)\n",
        "list_pred_test, list_path_test = model_inference(embedding_model,loader_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW-Cnw53Cw8M"
      },
      "source": [
        "**only for inception**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3FAYjlnDuRV"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(299),\n",
        "    transforms.CenterCrop(299),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWDphzAyDKIF"
      },
      "source": [
        "path_train = sorted(glob(\"Train/Train/*.png\"))\n",
        "images_train = ImageDataset(path_train,transform=preprocess)\n",
        "loader_train = DataLoader(images_train,batch_size=1,num_workers = 2)\n",
        "list_pred_train, list_path_train = model_inference(embedding_model,loader_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY7gPTnhDL2v"
      },
      "source": [
        "path_test = sorted(glob(\"Test/Test/*.png\"))\n",
        "images_test = ImageDataset(path_test,transform=preprocess)\n",
        "loader_test = DataLoader(images_test,batch_size=1,num_workers = 2)\n",
        "list_pred_test, list_path_test = model_inference(embedding_model,loader_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hurptPzeBxDY"
      },
      "source": [
        "## KNN training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzuVxe058t7Z"
      },
      "source": [
        "list_label_train = [int(path.split(\"_\")[-2]) for path in [p[0] for p in list_path_train]]\n",
        "X_train = np.stack(list_pred_train, axis=0)\n",
        "y_train = np.array(list_label_train)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l_DVkhrBxDY"
      },
      "source": [
        "pipe = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=500))\n",
        "pipe.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNL5bIOZBxDZ"
      },
      "source": [
        "pipe = make_pipeline(StandardScaler(), GaussianNB())\n",
        "pipe.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFY3gbKY8wc9"
      },
      "source": [
        "#Choose the cell above or this one. The cell above looks better\n",
        "#knn_model = KNeighborsClassifier(n_neighbors=500)\n",
        "#knn_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G396mXKpBxDb"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQezHVmX8zB_"
      },
      "source": [
        "X_test = np.stack(list_pred_test, axis=0)\n",
        "pred_knn_proba = pipe.predict_proba(X_test)    "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKqYJPIJ81RU"
      },
      "source": [
        "top_k = np.argsort(pred_knn_proba.copy(), axis=1)[:, -20:]\n",
        "np.save(\"top_k.npy\",top_k)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqC-86R-BxDc"
      },
      "source": [
        "## Submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTzVlUt8BxDc"
      },
      "source": [
        "def submission(top_k,list_path_test):\n",
        "    import csv\n",
        "    with open('submission.csv', mode='w') as csv_file:\n",
        "      fieldnames = ['file_name', 'label']\n",
        "      writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "      writer.writeheader()\n",
        "      for (i,pred),path in zip(enumerate(top_k),list_path_test):\n",
        "        best_labels = \" \".join([str(a) for a in top_k[i][::-1]])\n",
        "        writer.writerow({'file_name': path[0], 'label':best_labels})\n",
        "\n",
        "submission(top_k,list_path_test)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkyuX7cFBxDd"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBqZ7BBFBxDd"
      },
      "source": [
        "nb = 5\n",
        "nb_pred = 10\n",
        "fig,ax = plt.subplots(nb_pred,nb+1,figsize=(18,35))\n",
        "for i in range(nb_pred):\n",
        "    image_test_i = images_test[i][0].permute(1,2,0).numpy()\n",
        "    first_n_pred = top_k[i][-nb:][::-1]\n",
        "    ax[i,0].imshow(image_test_i)\n",
        "    ax[i,0].set_title(\"Test image n°{}\".format(i))\n",
        "    for j,n in enumerate(first_n_pred):\n",
        "        a = np.where(list_label_train==n)[0][0]\n",
        "        image_pred_i = images_train[a][0].permute(1,2,0).numpy()\n",
        "        ax[i,j+1].imshow(image_pred_i)\n",
        "        ax[i,j+1].set_title(\"Prediction n°{}, Time serie n° {}\".format(j,n))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}